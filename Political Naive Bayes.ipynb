{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 Assignment 4.1 Text Classification\n",
    "\n",
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating SQL connection to SQLite database\n",
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store speech and party\n",
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute('SELECT * FROM conventions')\n",
    "\n",
    "for row in query_results :\n",
    "    # store the results in convention_data\n",
    "    convention_data.append([row[5], row[0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a best practice to close up your DB connection when you're done\n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Iâ€™m John Peterson, owner of a second generation metal fabrication business called Schuette Metals. Weâ€™ve been stamping our products and services made in the USA since 1957. My brother and I purchased the business from my uncles almost 38 years ago. What was a 12 person shop has now grown into a company employing 165 people today. Like most companies that are successful over the long run, we had to reinvent ourselves as the market changed. Six years ago, we invested heavily in our business just as a greatest recession appeared. Barack Obama and Joe Biden, two career politicians who knew nothing about business, couldnâ€™t get the government out of our way. And it put our business in a tailspin. Sadly, we were forced to make decisions which included cutting staff, a torturous experience when our employees are like family. The Obama- Biden era banking regulations left us no choice. It tied our lenders hands and deprived us of the lifeblood of our business capital.',\n",
       "  'Republican'],\n",
       " ['California, home to our next Vice President Kamala Harris, casts 231 votes for Bernie Sanders and 263 votes for our next President, Joe Biden.',\n",
       "  'Democratic'],\n",
       " ['More than anything chose a man of faith and conscience, heâ€™ll be a precedent for Americans of all face as well as people of conscience who practice no particular faith. Joeâ€™s faith is really about our future, about a world with less suffering and more justice, where weâ€™re better stewards of creation, where we have a more just immigration policy, and where we call out and confront the original sins of this nation, the sins of slavery and racism. Joe knows these are central issues in this election, and for him, theyâ€™re rooted in faith.',\n",
       "  'Democratic'],\n",
       " ['Oklahoma.', 'Republican'],\n",
       " ['There is my team. You guys build America, not Wall Street. You build America, right.',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2024 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_sent_data = []\n",
    "\n",
    "for speech, party in convention_data :\n",
    "    conv_sent_data.append([sent_tokenize(speech), party])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['So before we show you a film about our dadâ€™s journey, we wanted to give Beau the last word.',\n",
       "   'Beau.'],\n",
       "  'Democratic'],\n",
       " [['This is a different kind of convention.'], 'Democratic'],\n",
       " [['He had been deported in September and had come back in October to terrorize our community.',\n",
       "   'I am extremely grateful to President Trump and the FBI for their efforts to deliver justice for Jackie and all of the other innocent victims of violent crime.',\n",
       "   'I am honored to support the President because he is supporting us.',\n",
       "   'I know he will never stop fighting for justice, for law and order, for peace, security in our communities.'],\n",
       "  'Republican'],\n",
       " [['That I will bear arms.'], 'Republican'],\n",
       " [['They didnâ€™t want to hear Bidenâ€™s hollow words of empathy.',\n",
       "   'They wanted their jobs back.',\n",
       "   'As Vice President, he supported the transpacific partnership, which would have been a death sentence for the US auto industry.',\n",
       "   'He backed the horrendous South Korea trade deal, which took many jobs from our country, and which Iâ€™ve reversed and made a great deal for our country.',\n",
       "   'He repeatedly supported mass amnesty for illegal immigrants.',\n",
       "   'He voted for the Iraq war.',\n",
       "   'He opposed the mission to take out Osama bin Laden.',\n",
       "   'He opposed killing Soleimani.',\n",
       "   'He oversaw the rise of ISIS and cheered the rise of China as a positive development for America and the world.',\n",
       "   'Some positive development.',\n",
       "   'Thatâ€™s why China supports Joe Biden and desperately wants him to win.',\n",
       "   'I can tell you that upon very good information.',\n",
       "   'China would own our country if Joe Biden got elected.',\n",
       "   'Unlike Biden, I will hold them fully accountable for the tragedy that they caused all over the world, they caused.',\n",
       "   'In recent months, our nation and the world has been hit by the once in a century pandemic that China allowed to spread around the globe.',\n",
       "   'They could have stopped it, but they allowed it to come out.',\n",
       "   'We are grateful to be joined tonight by several of our incredible nurses and first responders.',\n",
       "   'Please stand and accept our profound thanks and gratitude.',\n",
       "   'Many Americans, including me, have sadly lost friends and cherished loved ones to this horrible disease.',\n",
       "   'As one nation, we mourn, we grieve, and we hold in our hearts forever the memories of all of those lives that have been so tragically taken, so unnecessary.',\n",
       "   'In their honor, we will unite, in their memory we will overcome.',\n",
       "   'When the China virus hit, we launched the largest national mobilization since World War II.',\n",
       "   'Invoking the Defense Production Act, we produced the worldâ€™s largest supply of ventilators, not a single American who has needed a ventilator has been denied a ventilator, which is a miracle.',\n",
       "   'Good job heading the task force by our great Vice President.',\n",
       "   'Thank you very much, Mike, please, please stand up.'],\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps: \n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation)\n",
    "tw_punct = punctuation - {\"#\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform tokenization and normalization\n",
    "\n",
    "def get_cleaned_tokens(speech) :\n",
    "    \n",
    "    # Joining list of speeches into a single string\n",
    "    sentence = ' '.join(speech)\n",
    "    \n",
    "    # Removing punctuation\n",
    "    sentence = \"\".join([char for char in sentence if char not in tw_punct])\n",
    "\n",
    "    # Case folding and tokenization \n",
    "    sentence = [token.lower().strip() for token in sentence.split()]\n",
    "    \n",
    "    # Removing tokens that don't contain alphabetic characters\n",
    "    sentence = [token for token in sentence if token.isalpha()]\n",
    "  \n",
    "    # Removing stop words\n",
    "    sentence = [token for token in sentence if token not in sw]\n",
    "        \n",
    "    # Joining tokens into a string\n",
    "    sentence = ' '.join(sentence)\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time fight believe join us', 'Democratic'),\n",
       " ('inaudible smiling okay', 'Democratic'),\n",
       " ('future really rests investment going investing trillion infrastructure ports bridges highways making sure access things really make difference like solar facility outside harrisburg scranton boy central pennsylvania okay northeast keep faith guys',\n",
       "  'Democratic'),\n",
       " ('means much families grow single parent home serve boys girls right daily basis even covid us give moms opportunity take money check paycheck home back children able go school may opportunity otherwise means much us much greater opportunity individuals come together walk life people really able see positive change filled hope especially throughout time',\n",
       "  'Republican'),\n",
       " ('failed american people catastrophically four years ago came convention said new yorkers know con see one tonight asking vote donald trump bad guy urging vote done bad job today unemployment historic highs small businesses struggling survive way ran mayor spent years running business started scratch want ask small business owners employees one question question everyone would rehire work someone ran business ground always best even hurts company whose reckless decisions put danger spends time tweeting working answer hell would ever rehire donald trump another four years',\n",
       "  'Democratic')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_conv_sent_data = [] # list of tuples (sentence, party), with sentence cleaned\n",
    "\n",
    "for speech_party in conv_sent_data :\n",
    "    \n",
    "    # passing index 0 to clean and extract the tokens\n",
    "    processed_speech = get_cleaned_tokens(speech_party[0])\n",
    "    \n",
    "    clean_conv_sent_data.append((processed_speech, speech_party[1]))\n",
    "\n",
    "random.choices(clean_conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2255 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [word for text, party in clean_conv_sent_data for word in text.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text, fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    ret_dict = dict()\n",
    "    \n",
    "    for token in text.split() :\n",
    "        if token in fw :\n",
    "            ret_dict[token] = True\n",
    "      \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"obama was the president\",feature_words)==\n",
    "       {'obama':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
      "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.3 : 1.0\n",
      "                 destroy = True           Republ : Democr =     17.1 : 1.0\n",
      "                supports = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.9 : 1.0\n",
      "                preserve = True           Republ : Democr =     15.1 : 1.0\n",
      "                  signed = True           Republ : Democr =     15.1 : 1.0\n",
      "              appreciate = True           Republ : Democr =     14.0 : 1.0\n",
      "                freedoms = True           Republ : Democr =     14.0 : 1.0\n",
      "                 private = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     10.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.3 : 1.0\n",
      "                 special = True           Republ : Democr =     10.3 : 1.0\n",
      "                   trade = True           Republ : Democr =     10.0 : 1.0\n",
      "                everyday = True           Republ : Democr =      9.9 : 1.0\n",
      "                   local = True           Republ : Democr =      9.9 : 1.0\n",
      "                 allowed = True           Republ : Democr =      9.7 : 1.0\n",
      "                   elect = True           Democr : Republ =      9.6 : 1.0\n",
      "                   moved = True           Republ : Democr =      9.0 : 1.0\n",
      "                   bless = True           Republ : Democr =      9.0 : 1.0\n",
      "                    land = True           Republ : Democr =      8.9 : 1.0\n",
      "                  agenda = True           Republ : Democr =      8.8 : 1.0\n",
      "               countries = True           Republ : Democr =      8.8 : 1.0\n",
      "                   crime = True           Republ : Democr =      8.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a little prose here about what you see in the classifier. Anything odd or interesting?**\n",
    "\n",
    "### My Observations\n",
    "\n",
    "The accuracy of the classifier is 0.498 suggesting that it correctly predicts 50% (approx.) of the instances reflecting a moderate performance and it does not distinguish well between the two classes (Republican and Democratic). From the most informative features, we observe that the term \"enforcement\" is 27.5 times more likely to appear in Republican contexts, implying a stronger association with the party. Likewise, the term \"votes\" ' appears 21.6 times more often in Democratic texts, showing its frequent use in discussions tied to the Democratic party.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results output shows that the strings are encoded in base format. Hence we decode the tweets using decode() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "for candidate, party, tweet in results :\n",
    "    \n",
    "    # Decode the byte string\n",
    "    decoded_tweet = tweet.decode('utf-8')\n",
    "    tweet_data.append((decoded_tweet, party))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweets) :\n",
    "    \n",
    "    # Removing punctuation\n",
    "    tweets = \"\".join([char for char in tweets if char not in tw_punct])\n",
    "    \n",
    "    # Case folding and tokenization \n",
    "    tweets = [token.lower().strip() for token in tweets.split()]\n",
    "  \n",
    "    # Removing stop words\n",
    "    tweets = [token for token in tweets if token not in sw]\n",
    "\n",
    "    # Joining tokens into a string\n",
    "    tweets = ' '.join(tweets)\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_data = []\n",
    "\n",
    "for tweet_party in tweet_data :\n",
    "    \n",
    "    processed_tweet = clean_tweets(tweet_party[0])\n",
    "    clean_tweet_data.append([processed_tweet, tweet_party[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(clean_tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv',\n",
       "  'Democratic'],\n",
       " ['go tribe #rallytogether httpstco0nxutfl9l5', 'Democratic'],\n",
       " ['apparently trump thinks easy students overwhelmed crushing burden debt pay student loans #trumpbudget httpstcockyqo5t0qh',\n",
       "  'Democratic'],\n",
       " ['weâ€™re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpv0vmiz3',\n",
       "  'Republican'],\n",
       " ['letâ€™s make even greater #kag ðŸ‡ºðŸ‡¸ httpstcoy9qozd5l2z', 'Republican'],\n",
       " ['1hr cavs tie series 22 im #allin216 repbarbaralee scared #roadtovictory',\n",
       "  'Democratic'],\n",
       " ['congrats belliottsd new gig sd city hall glad continue serveâ€¦ httpstcofkvmw3cqdi',\n",
       "  'Democratic'],\n",
       " ['really close 3500 raised toward match right whoot thatâ€™s 7000 nonmath majors room ðŸ˜‚ help us get httpstcotu34c472sd httpstcoqsdqkypsmc',\n",
       "  'Democratic'],\n",
       " ['today comment period potusâ€™s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn',\n",
       "  'Democratic'],\n",
       " ['celebrated icseastlaâ€™s 22 years eastside commitment amp saluted community leaders last nightâ€™s awards dinner httpstco7v7gh8givb',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe #rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans #trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: weâ€™re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: letâ€™s make even greater #kag ðŸ‡ºðŸ‡¸ httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: 1hr cavs tie series 22 im #allin216 repbarbaralee scared #roadtovictory\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serveâ€¦ httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close 3500 raised toward match right whoot thatâ€™s 7000 nonmath majors room ðŸ˜‚ help us get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potusâ€™s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastlaâ€™s 22 years eastside commitment amp saluted community leaders last nightâ€™s awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(clean_tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(clean_tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3592, 'Democratic': 686}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4738, 'Democratic': 986})})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "**Write a little about what you see in the results**\n",
    "\n",
    "The results show that for tweets from the Republican party, the classifier correctly identified 3,592 as Republican but misclassified 686 as Democratic. For tweets from the Democratic party, it accurately classified 986 as Democratic but incorrectly labeled 4,738 as Republican. This indicates that the classifier is better at identifying Republican tweets compared to Democratic ones. The imbalance suggests that the model might have a bias towards classifying tweets as Republican, or it may need additional features to better differentiate between the two parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
